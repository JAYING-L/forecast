{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e603e76e",
   "metadata": {},
   "source": [
    "# 1.导入包及数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd57ec86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0      date  open  high   low  close  volume    hold  settle  \\\n0           1  2010/1/4  4080  4090  4049   4057  321838  284296       0   \n1           2  2010/1/5  4067  4082  4060   4066  253640  283384       0   \n2           3  2010/1/6  4066  4194  4057   4154  860812  352830       0   \n3           4  2010/1/7  4165  4188  3975   4044  705704  297236       0   \n4           5  2010/1/8  4040  4050  3947   3981  526594  270074       0   \n\n    return  volatility  \n0  0.00000         0.0  \n1  0.00222         0.0  \n2  0.02141         0.0  \n3 -0.02684         0.0  \n4 -0.01570         0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>hold</th>\n      <th>settle</th>\n      <th>return</th>\n      <th>volatility</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2010/1/4</td>\n      <td>4080</td>\n      <td>4090</td>\n      <td>4049</td>\n      <td>4057</td>\n      <td>321838</td>\n      <td>284296</td>\n      <td>0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2010/1/5</td>\n      <td>4067</td>\n      <td>4082</td>\n      <td>4060</td>\n      <td>4066</td>\n      <td>253640</td>\n      <td>283384</td>\n      <td>0</td>\n      <td>0.00222</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2010/1/6</td>\n      <td>4066</td>\n      <td>4194</td>\n      <td>4057</td>\n      <td>4154</td>\n      <td>860812</td>\n      <td>352830</td>\n      <td>0</td>\n      <td>0.02141</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2010/1/7</td>\n      <td>4165</td>\n      <td>4188</td>\n      <td>3975</td>\n      <td>4044</td>\n      <td>705704</td>\n      <td>297236</td>\n      <td>0</td>\n      <td>-0.02684</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2010/1/8</td>\n      <td>4040</td>\n      <td>4050</td>\n      <td>3947</td>\n      <td>3981</td>\n      <td>526594</td>\n      <td>270074</td>\n      <td>0</td>\n      <td>-0.01570</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from vmdpy import VMD  \n",
    "import akshare as ak #大豆数据集\n",
    "from scipy.fftpack import fft ##傅里叶级数\n",
    "import pkuseg   #分词包\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer #sklearn的统计词特征包\n",
    "from sklearn.feature_extraction.text import TfidfTransformer #sklearn的TF-IDF包\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#下载数据\n",
    "Data=pd.read_csv(\"data.csv\")\n",
    "Data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505c2c8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-f20343b2a2a7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#数据处理\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_datetime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mData\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mData\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m'Unnamed: 0'\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0minplace\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mData\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36mdrop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   4161\u001B[0m                 \u001B[0mweight\u001B[0m  \u001B[1;36m1.0\u001B[0m     \u001B[1;36m0.8\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4162\u001B[0m         \"\"\"\n\u001B[1;32m-> 4163\u001B[1;33m         return super().drop(\n\u001B[0m\u001B[0;32m   4164\u001B[0m             \u001B[0mlabels\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4165\u001B[0m             \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36mdrop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   3885\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[1;32min\u001B[0m \u001B[0maxes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3886\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mlabels\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3887\u001B[1;33m                 \u001B[0mobj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_drop_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlevel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3888\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3889\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0minplace\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m_drop_axis\u001B[1;34m(self, labels, axis, level, errors)\u001B[0m\n\u001B[0;32m   3919\u001B[0m                 \u001B[0mnew_axis\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlevel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3920\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3921\u001B[1;33m                 \u001B[0mnew_axis\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3922\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreindex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0maxis_name\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnew_axis\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3923\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mdrop\u001B[1;34m(self, labels, errors)\u001B[0m\n\u001B[0;32m   5280\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmask\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0many\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5281\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0merrors\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;34m\"ignore\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5282\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{labels[mask]} not found in axis\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   5283\u001B[0m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mindexer\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m~\u001B[0m\u001B[0mmask\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5284\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdelete\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#数据处理\n",
    "pd.to_datetime(Data.date)\n",
    "Data.drop(columns={'Unnamed: 0'},inplace=True)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2383f20b",
   "metadata": {},
   "source": [
    "##### **标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7603cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#标准化数据\n",
    "# array=[Data['return'],Data['volatility']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe0ccda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.38370969, 0.        ],\n       [0.39633695, 0.        ],\n       [0.50548888, 0.        ],\n       ...,\n       [0.39559752, 0.14371025],\n       [0.39855526, 0.14600355],\n       [0.40737159, 0.14992982]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax = preprocessing.MinMaxScaler()\n",
    "data_minmax = minmax.fit_transform(Data[['return','volatility']])\n",
    "data_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407fc1a",
   "metadata": {},
   "source": [
    "# 2.VMD分解 Return&Volatility "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63298e",
   "metadata": {},
   "source": [
    "### vmd参数设置及绘制分解模态图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69204bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.导入文件，可以指定列也可以，就是usecols\n",
    "filename= '/Volumes/本机/paper/futures voality forcaseting/VMD_BiLSTM_A0/Data/data.csv'\n",
    "f = pd.read_csv(filename,usecols=[9,10])\n",
    "\n",
    "#vmd包参数设置并执行VMD\n",
    "alpha = 5000       #宽带限制，一般为数据点的1.5-2倍  \n",
    "tau = 0.           # 噪声限制 (no strict fidelity enforcement)  \n",
    "K = 11             # 分解模态个数  \n",
    "DC = 0             # 合成信号若无常量则为0；若含常量，则其取值为 1；  \n",
    "init = 1           # 初始化ω值,当初始化为1时,均匀分布产生的随机数； \n",
    "tol = 1e-7         # 控制误差大小常量，决定精度与迭代次数\n",
    "\n",
    "u, u_hat, omega = VMD(f['return'], alpha, tau, K, DC, init, tol)  \n",
    "u1,u1_hat,omega1 = VMD(f['volatility'], alpha, tau, K, DC, init, tol)  \n",
    "#绘制分解模态图\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(u.T)\n",
    "plt.title('Decomposed modes of return')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(u1.T)\n",
    "plt.title('Decomposed modes of volatility')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e6562b",
   "metadata": {},
   "source": [
    "### IMF of return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a9d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#未分解前的图\n",
    "fig_return = plt.figure()\n",
    "plt.plot(f['return'])\n",
    "fig_return.suptitle('Original input signal and its components')\n",
    "\n",
    "#循环每个分解模态的\n",
    "for i in range(K):\n",
    "    plt.figure(figsize=(5,5), dpi=100)\n",
    "    plt.subplot(K,1,i+1)\n",
    "    plt.plot(u[i,:], linewidth=0.2, c='r')\n",
    "    plt.ylabel('IMF{}'.format(i+1))\n",
    "    \n",
    "    #每个模态的中心频率\n",
    "for i in range(K):\n",
    "    plt.figure(figsize=(5,5), dpi=100)\n",
    "    plt.subplot(K,1,i+1)\n",
    "    plt.plot(abs(fft(u[i,:])))\n",
    "    plt.ylabel('IMF{}'.format(i+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b2353d",
   "metadata": {},
   "source": [
    "### IMF of volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403b35ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#未分解前的图\n",
    "fig_volatility = plt.figure()\n",
    "plt.plot(f['volatility'])\n",
    "fig_volatility.suptitle('Original input signal and its components OF volatility')\n",
    "\n",
    "#循环每个分解模态的\n",
    "for i in range(K):\n",
    "    plt.figure(figsize=(5,5), dpi=100)\n",
    "    plt.subplot(K,1,i+1)\n",
    "    plt.plot(u1[i,:], linewidth=0.2, c='r')\n",
    "    plt.ylabel('IMF{}'.format(i+1))\n",
    "    \n",
    "    #每个模态的中心频率\n",
    "for i in range(K):\n",
    "    plt.figure(figsize=(5,5), dpi=100)\n",
    "    plt.subplot(K,1,i+1)\n",
    "    plt.plot(abs(fft(u1[i,:])))\n",
    "    plt.ylabel('IMF{}'.format(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429d24a",
   "metadata": {},
   "source": [
    "# 3.文本处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b3d2f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath1='/Volumes/本机/paper/futures voality forcaseting/VMD_BiLSTM_A0/Data/text.csv'\n",
    "text=pd.read_csv(filepath1)\n",
    "pd.to_datetime(text.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad58ce5",
   "metadata": {},
   "source": [
    "### (1).文本预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865eca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=text.title\n",
    "titles1=[]\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    textgo = re.sub('[^\\u4e00-\\u9fa5_a-zA-Z0-9]','',str(titles[i]))\n",
    "    titles1.append(textgo) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d94cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(titles1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998254f",
   "metadata": {},
   "source": [
    "###  (2).文本分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75311c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(titles1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee013741",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = pkuseg.pkuseg() # 以默认配置加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ea9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "textcut=[]\n",
    "for j in titles1:  \n",
    "    textfo=seg.cut( j )  # 进行分词\n",
    "    textcut.append(textfo)\n",
    "    \n",
    "text_cut=pd.Series(textcut)##list换series，然后放入表中\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34003c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.insert(loc=1,column='text_cut',value=text_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef47c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17acb6b4",
   "metadata": {},
   "source": [
    "###  (3).去除停用词（采用中文停用词表）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1519d788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def stopwordslist(filepath):   # 定义函数创建停用词列表\n",
    "    stopword = [line.strip() for line in open(filepath, 'r').readlines()]    #以行的形式读取停用词表，同时转换为列表\n",
    "    return stopword\n",
    "\n",
    "filepath='/Volumes/本机/learning/NLP/stopwords/stopwords-master/cn_stopwords.txt'\n",
    "stopwords = stopwordslist(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cut[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d81aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(text_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c672fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastsentences=[]\n",
    "lastsentences_str=[]##增加列表内是字符串的一项，方便进行向量化处理\n",
    "for i in range(len(text_cut)):     #for循环遍历分词后的每个词语\n",
    "    lastsentence=[]\n",
    "    for word in text_cut[i]:\n",
    "        if word not in stopwords:     #判断分词后的词语是否在停用词表内\n",
    "            lastsentence.append(word)\n",
    "            lastsentence_str=' '.join(lastsentence)\n",
    "    lastsentences.append(lastsentence)\n",
    "    lastsentences_str.append(lastsentence_str)\n",
    "text_cut_stopwords=pd.Series(lastsentences)\n",
    "text_cut_stopwords_str=pd.Series(lastsentences_str)\n",
    "text.insert(loc=2,column='text_cut_stopwords',value=text_cut_stopwords)\n",
    "text.insert(loc=2,column='text_cut_stopwords_str',value=text_cut_stopwords_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9351669",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastsentences_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc338ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.text_cut_stopwords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9eb25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57769a3c",
   "metadata": {},
   "source": [
    "###  (4).向量转换（BoW & TF-IDF）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer和TfidfTransformer默认学习list里的str（在str中以空格为分断），所以对象应该换成list(‘str1’,‘str2’,...)\n",
    "vectorizer = CountVectorizer(min_df=1,max_df=0.8) ##创建单词表时，忽略占比超过百分之五十的词 以及 出现数少于2的词\n",
    "transformer = TfidfTransformer() \n",
    "X = vectorizer.fit_transform(lastsentences_str)#学习词汇，返回文档术语与矩阵\n",
    "feature_name = vectorizer.get_feature_names()#显示特征名\n",
    "tfidf = transformer.fit_transform(X)  #把已经生成的文档矩阵换成TF-IDF矩阵\n",
    "tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3416ba",
   "metadata": {},
   "source": [
    "### (5).情感分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40165a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}